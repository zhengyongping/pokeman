#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§ç¿»è¯‘å¯¹æ¨¡ä»¿æ¼”ç¤ºç¨‹åº
æä¾›æ›´ç›´è§‚çš„ç•Œé¢å’Œæ›´å¤šåŠŸèƒ½é€‰é¡¹
"""

import json
import os
import re
import random
from datetime import datetime
from typing import Dict, List, Any

class AdvancedTranslationMimic:
    def __init__(self):
        self.pairs_directory = "individual_pairs"
        self.translation_pairs = []
        self.patterns = self.load_patterns()
        self.load_data()
    
    def load_patterns(self):
        """åŠ è½½ç¿»è¯‘æ¨¡å¼"""
        return {
            'pokemon_names': {
                'Garchomp': 'çƒˆå’¬é™†é²¨', 'Giratina-O': 'éª‘æ‹‰å¸çº³-èµ·æº', 'Dondozo': 'åƒå¼éœ¸',
                'Mega Latias': 'è¶…çº§æ‹‰å¸äºšæ–¯', 'Mega Scizor': 'è¶…çº§å·¨é’³è³è‚', 'Ferrothorn': 'åšæœå“‘é“ƒ',
                'Corviknight': 'é’¢é“ é¸¦', 'Tapu Lele': 'å¡ç’Â·è¶è¶', 'Iron Valiant': 'é“æ­¦è€…',
                'Weavile': 'ç›ç‹ƒæ‹‰', 'Heatran': 'å¸­å¤šè“æ©', 'Toxapex': 'è¶…åæ˜Ÿ',
                'Gliscor': 'å¤©èç‹', 'Ting-Lu': 'å¤é¼é¹¿', 'Volcarona': 'ç«ç¥è›¾',
                'Raging Bolt': 'çŒ›é›·é¼“', 'Urshifu-R': 'æ­¦é“ç†Šå¸ˆ-è¿å‡»æµ', 'Landorus-T': 'åœŸåœ°äº‘-çµå…½',
                'Rotom-W': 'æ¸…æ´—æ´›æ‰˜å§†', 'Alomomola': 'ä¿å§†æ›¼æ³¢', 'Galarian Slowking': 'ä¼½å‹’å°”å‘†å‘†ç‹',
                'Ogerpon-W': 'å„è¯¡æ¤ª-æ°´äº•é¢å…·', 'Mega Tyranitar': 'è¶…çº§ç­åŸºæ‹‰æ–¯', 'Zamazenta': 'è—ç›ç„¶ç‰¹',
                'Clefable': 'çš®å¯è¥¿', 'Kartana': 'çº¸å¾¡å‰‘', 'Rillaboom': 'è½°æ“‚é‡‘åˆšçŒ©',
                'Ho-Oh': 'å‡¤ç‹', 'Arceus-Fairy': 'é˜¿å°”å®™æ–¯-å¦–ç²¾', 'Arceus-Water': 'é˜¿å°”å®™æ–¯-æ°´'
            },
            'moves': {
                'Shadow Ball': 'å½±å­çƒ', 'Hex': 'ç¥¸ä¸å•è¡Œ', 'Calm Mind': 'å†¥æƒ³',
                'Will-O-Wisp': 'ç£·ç«', 'Stone Edge': 'å°–çŸ³æ”»å‡»', 'Thunder Wave': 'ç”µç£æ³¢',
                'Poltergeist': 'çµéªš', 'Ruination': 'å¤§ç¾éš¾', 'Dragon Dance': 'é¾™ä¹‹èˆ',
                'Liquidation': 'æ°´æµè£‚ç ´', 'Waterfall': 'æ”€ç€‘', 'Curse': 'è¯…å’’',
                'Body Press': 'æ‰‘å‡»', 'Scale Shot': 'é³å°„', 'Fire Fang': 'ç«ç„°ç‰™',
                'Psychic': 'ç²¾ç¥å¼ºå¿µ', 'Psyshock': 'ç²¾ç¥å†²å‡»', 'Aura Sphere': 'æ³¢å¯¼å¼¹',
                'Ice Beam': 'å†°å†»å…‰æŸ', 'Draco Meteor': 'æµæ˜Ÿç¾¤', 'Spikes': 'æ’’è±',
                'Stealth Rock': 'éšå½¢å²©', 'Toxic': 'å‰§æ¯’', 'Substitute': 'æ›¿èº«'
            },
            'abilities': {
                'Unaware': 'çº¯æœ´', 'Levitate': 'é£˜æµ®', 'Intimidate': 'å¨å“'
            },
            'items': {
                'Heavy-Duty Boots': 'åšåº•é´', 'Leftovers': 'åƒå‰©çš„ä¸œè¥¿',
                'Loaded Dice': 'æœºå˜éª°å­', 'Choice Scarf': 'è®²ç©¶å›´å·¾'
            },
            'types': {
                'Dragon': 'é¾™', 'Steel': 'é’¢', 'Fire': 'ç«', 'Water': 'æ°´',
                'Grass': 'è‰', 'Electric': 'ç”µ', 'Psychic': 'è¶…èƒ½åŠ›', 'Fighting': 'æ ¼æ–—',
                'Poison': 'æ¯’', 'Ground': 'åœ°é¢', 'Flying': 'é£è¡Œ', 'Bug': 'è™«',
                'Rock': 'å²©çŸ³', 'Ghost': 'å¹½çµ', 'Ice': 'å†°', 'Dark': 'æ¶', 'Fairy': 'å¦–ç²¾'
            },
            'phrases': {
                'setup sweeper': 'æ¸…åœºæ‰‹', 'physical bulk': 'ç‰©ç†è€ä¹…',
                'win condition': 'è·èƒœç‚¹', 'entry hazards': 'é’‰å­',
                'priority moves': 'å…ˆåˆ¶æ‹›å¼', 'offensive pressure': 'è¿›æ”»å‹åŠ›',
                'defensive typing': 'é˜²å¾¡å±æ€§', 'utility Pokemon': 'åŠŸèƒ½å‹å®å¯æ¢¦',
                'bulky teams': 'è€ä¹…å‘é˜Ÿä¼', 'hyper offense': 'hoé˜Ÿä¼',
                'dual screens': 'åŒå¢™', 'STAB boost': 'å±æ€§ä¸€è‡´åŠ æˆ',
                'immune to': 'å…ç–«', 'super effective': 'æ•ˆæœæ‹”ç¾¤',
                'not very effective': 'æ•ˆæœä¸ä½³', 'chip damage': 'æ¶ˆè€—',
                'set up': 'å¼ºåŒ–', 'sweep': 'æ¸…åœº', 'recovery': 'å›å¤',
                'pivot': 'ä¸­è½¬', 'hazard removal': 'æ¸…é’‰'
            }
        }
    
    def load_data(self):
        """åŠ è½½ç¿»è¯‘å¯¹æ•°æ®"""
        if not os.path.exists(self.pairs_directory):
            print(f"âŒ ç›®å½• {self.pairs_directory} ä¸å­˜åœ¨")
            return
        
        for filename in os.listdir(self.pairs_directory):
            if filename.endswith('.json'):
                filepath = os.path.join(self.pairs_directory, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if 'english' in data and 'chinese' in data:
                            self.translation_pairs.append(data)
                except Exception as e:
                    continue
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(self.translation_pairs)} ä¸ªç¿»è¯‘å¯¹")
    
    def translate_text(self, text: str) -> str:
        """ç¿»è¯‘æ–‡æœ¬"""
        result = text
        
        # åº”ç”¨å„ç§ç¿»è¯‘æ¨¡å¼
        for category, patterns in self.patterns.items():
            for en_term, cn_term in patterns.items():
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œç²¾ç¡®åŒ¹é…
                pattern = r'\b' + re.escape(en_term) + r'\b'
                result = re.sub(pattern, cn_term, result, flags=re.IGNORECASE)
        
        return result
    
    def analyze_translation(self, english: str, chinese: str) -> Dict[str, float]:
        """åˆ†æç¿»è¯‘è´¨é‡"""
        # è®¡ç®—è¦†ç›–ç‡
        words = english.split()
        translated_count = 0
        
        for word in words:
            clean_word = re.sub(r'[^a-zA-Z-]', '', word)
            if any(clean_word.lower() in term.lower() 
                   for patterns in self.patterns.values() 
                   for term in patterns.keys()):
                translated_count += 1
        
        coverage = translated_count / len(words) if words else 0
        
        # è®¡ç®—ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', chinese))
        total_chars = len(chinese)
        chinese_ratio = chinese_chars / total_chars if total_chars > 0 else 0
        
        # è®¡ç®—å®Œæ•´åº¦
        length_ratio = len(chinese) / len(english) if english else 0
        completeness = min(length_ratio, 1.0)
        
        return {
            'coverage': coverage,
            'chinese_ratio': chinese_ratio,
            'completeness': completeness,
            'overall_quality': (coverage + chinese_ratio + completeness) / 3
        }
    
    def generate_mimic_pair(self, base_text: str = None) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡ä»¿ç¿»è¯‘å¯¹"""
        if base_text is None:
            base_pair = random.choice(self.translation_pairs)
            base_text = base_pair['english']
        
        translated = self.translate_text(base_text)
        quality = self.analyze_translation(base_text, translated)
        
        return {
            'english': base_text,
            'chinese': translated,
            'quality': quality,
            'timestamp': datetime.now().isoformat()
        }
    
    def create_variation(self, text: str) -> str:
        """åˆ›å»ºæ–‡æœ¬å˜ä½“"""
        # éšæœºæ›¿æ¢ä¸€äº›å®å¯æ¢¦åç§°
        pokemon_names = list(self.patterns['pokemon_names'].keys())
        
        for _ in range(2):  # æœ€å¤šæ›¿æ¢2æ¬¡
            if len(pokemon_names) >= 2:
                old_name = random.choice(pokemon_names)
                new_name = random.choice(pokemon_names)
                if old_name != new_name and old_name in text:
                    text = text.replace(old_name, new_name, 1)
        
        return text
    
    def interactive_demo(self):
        """äº¤äº’å¼æ¼”ç¤º"""
        print("\n" + "="*60)
        print("ğŸ¯ é«˜çº§ç¿»è¯‘å¯¹æ¨¡ä»¿æ¼”ç¤ºç¨‹åº")
        print("="*60)
        
        if not self.translation_pairs:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„ç¿»è¯‘å¯¹æ•°æ®")
            return
        
        while True:
            print("\nğŸ“‹ å¯ç”¨åŠŸèƒ½:")
            print("1ï¸âƒ£  éšæœºç”Ÿæˆç¿»è¯‘å¯¹")
            print("2ï¸âƒ£  è‡ªå®šä¹‰æ–‡æœ¬ç¿»è¯‘")
            print("3ï¸âƒ£  ç”Ÿæˆæ–‡æœ¬å˜ä½“")
            print("4ï¸âƒ£  æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯")
            print("5ï¸âƒ£  æ‰¹é‡ç”Ÿæˆå¹¶ä¿å­˜")
            print("6ï¸âƒ£  é€€å‡ºç¨‹åº")
            
            try:
                choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (1-6): ").strip()
                
                if choice == '1':
                    self.demo_random_generation()
                elif choice == '2':
                    self.demo_custom_translation()
                elif choice == '3':
                    self.demo_text_variation()
                elif choice == '4':
                    self.demo_statistics()
                elif choice == '5':
                    self.demo_batch_generation()
                elif choice == '6':
                    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                    break
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
            
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
    
    def demo_random_generation(self):
        """æ¼”ç¤ºéšæœºç”Ÿæˆ"""
        print("\nğŸ² éšæœºç”Ÿæˆç¿»è¯‘å¯¹...")
        
        pair = self.generate_mimic_pair()
        
        print("\nğŸ“ åŸæ–‡:")
        print(f"   {pair['english'][:200]}..." if len(pair['english']) > 200 else f"   {pair['english']}")
        
        print("\nğŸ”„ è¯‘æ–‡:")
        print(f"   {pair['chinese'][:200]}..." if len(pair['chinese']) > 200 else f"   {pair['chinese']}")
        
        quality = pair['quality']
        print("\nğŸ“Š è´¨é‡è¯„ä¼°:")
        print(f"   è¦†ç›–ç‡: {quality['coverage']:.1%}")
        print(f"   ä¸­æ–‡æ¯”ä¾‹: {quality['chinese_ratio']:.1%}")
        print(f"   å®Œæ•´åº¦: {quality['completeness']:.1%}")
        print(f"   æ€»ä½“è´¨é‡: {quality['overall_quality']:.1%}")
    
    def demo_custom_translation(self):
        """æ¼”ç¤ºè‡ªå®šä¹‰ç¿»è¯‘"""
        print("\nâœï¸  è‡ªå®šä¹‰æ–‡æœ¬ç¿»è¯‘")
        text = input("è¯·è¾“å…¥è¦ç¿»è¯‘çš„è‹±æ–‡æ–‡æœ¬: ").strip()
        
        if not text:
            print("âŒ æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
            return
        
        pair = self.generate_mimic_pair(text)
        
        print("\nğŸ“ åŸæ–‡:")
        print(f"   {text}")
        
        print("\nğŸ”„ è¯‘æ–‡:")
        print(f"   {pair['chinese']}")
        
        quality = pair['quality']
        print("\nğŸ“Š è´¨é‡è¯„ä¼°:")
        print(f"   è¦†ç›–ç‡: {quality['coverage']:.1%}")
        print(f"   ä¸­æ–‡æ¯”ä¾‹: {quality['chinese_ratio']:.1%}")
        print(f"   å®Œæ•´åº¦: {quality['completeness']:.1%}")
        print(f"   æ€»ä½“è´¨é‡: {quality['overall_quality']:.1%}")
    
    def demo_text_variation(self):
        """æ¼”ç¤ºæ–‡æœ¬å˜ä½“ç”Ÿæˆ"""
        print("\nğŸ”€ æ–‡æœ¬å˜ä½“ç”Ÿæˆ")
        
        # é€‰æ‹©ä¸€ä¸ªåŸºç¡€æ–‡æœ¬
        base_pair = random.choice(self.translation_pairs)
        base_text = base_pair['english'][:300]  # é™åˆ¶é•¿åº¦
        
        print("\nğŸ“ åŸºç¡€æ–‡æœ¬:")
        print(f"   {base_text}...")
        
        # ç”Ÿæˆ3ä¸ªå˜ä½“
        print("\nğŸ”„ ç”Ÿæˆçš„å˜ä½“:")
        for i in range(3):
            variation = self.create_variation(base_text)
            translated = self.translate_text(variation)
            
            print(f"\n--- å˜ä½“ {i+1} ---")
            print(f"è‹±æ–‡: {variation[:150]}...")
            print(f"ä¸­æ–‡: {translated[:150]}...")
    
    def demo_statistics(self):
        """æ¼”ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯")
        print(f"\nğŸ“š æ•°æ®æ¦‚è§ˆ:")
        print(f"   ç¿»è¯‘å¯¹æ€»æ•°: {len(self.translation_pairs)}")
        
        print(f"\nğŸ¯ ç¿»è¯‘æ¨¡å¼ç»Ÿè®¡:")
        for category, patterns in self.patterns.items():
            print(f"   {category}: {len(patterns)} ä¸ªæ¨¡å¼")
        
        # åˆ†æç°æœ‰ç¿»è¯‘å¯¹çš„è´¨é‡
        if self.translation_pairs:
            print(f"\nğŸ” è´¨é‡åˆ†æ (å‰5ä¸ªç¿»è¯‘å¯¹):")
            for i, pair in enumerate(self.translation_pairs[:5], 1):
                quality = self.analyze_translation(pair['english'], pair['chinese'])
                print(f"   ç¿»è¯‘å¯¹ {i}: æ€»ä½“è´¨é‡ {quality['overall_quality']:.1%}")
    
    def demo_batch_generation(self):
        """æ¼”ç¤ºæ‰¹é‡ç”Ÿæˆ"""
        print("\nğŸ“¦ æ‰¹é‡ç”Ÿæˆç¿»è¯‘å¯¹")
        
        try:
            count = int(input("è¯·è¾“å…¥è¦ç”Ÿæˆçš„æ•°é‡ (1-20): ").strip())
            if not 1 <= count <= 20:
                print("âŒ æ•°é‡å¿…é¡»åœ¨1-20ä¹‹é—´")
                return
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
            return
        
        print(f"\nğŸ”„ æ­£åœ¨ç”Ÿæˆ {count} ä¸ªç¿»è¯‘å¯¹...")
        
        generated_pairs = []
        for i in range(count):
            pair = self.generate_mimic_pair()
            generated_pairs.append(pair)
            print(f"   è¿›åº¦: {i+1}/{count}")
        
        # è®¡ç®—å¹³å‡è´¨é‡
        avg_quality = sum(p['quality']['overall_quality'] for p in generated_pairs) / len(generated_pairs)
        
        print(f"\nâœ… ç”Ÿæˆå®Œæˆï¼å¹³å‡è´¨é‡: {avg_quality:.1%}")
        
        # ä¿å­˜é€‰é¡¹
        save = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶? (y/n): ").strip().lower()
        if save == 'y':
            filename = f"batch_generated_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            report = {
                'generation_date': datetime.now().isoformat(),
                'total_pairs': len(generated_pairs),
                'average_quality': avg_quality,
                'pairs': generated_pairs
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å·²ä¿å­˜åˆ°: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨é«˜çº§ç¿»è¯‘å¯¹æ¨¡ä»¿æ¼”ç¤ºç¨‹åº...")
    
    mimic = AdvancedTranslationMimic()
    mimic.interactive_demo()

if __name__ == "__main__":
    main()